{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"1yzEWqhIFfbV"},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torch.optim import lr_scheduler\n","import torch.backends.cudnn as cudnn\n","import numpy as np\n","import torchvision\n","from torchvision import datasets, models, transforms\n","import matplotlib.pyplot as plt\n","import time\n","import os\n","import copy\n","import random\n","\n","import os\n","import random\n","from sklearn.model_selection import train_test_split\n","import torch\n","from torchvision import datasets, transforms\n","from torch.utils.data import DataLoader, Subset"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"625q1cUXLdCE"},"outputs":[],"source":["def set_seed(seed):\n","    torch.manual_seed(seed)\n","    random.seed(seed)\n","    os.environ['PYTHONHASHSEED'] = str(seed)\n","    torch.backends.cudnn.benchmark = False\n","    torch.backends.cudnn.deterministic = True\n","\n","set_seed(100)"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":17,"status":"ok","timestamp":1683496904249,"user":{"displayName":"Purnasai Gudikandula","userId":"02824392492878909733"},"user_tz":-330},"id":"C1faPJhAID3x","outputId":"2e76f8a6-3509-47a6-f4fe-3317e5ae724c"},"outputs":[{"name":"stdout","output_type":"stream","text":["2.3.1+cu118\n"]}],"source":["print(torch.__version__)"]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":14,"status":"ok","timestamp":1683496905711,"user":{"displayName":"Purnasai Gudikandula","userId":"02824392492878909733"},"user_tz":-330},"id":"tX-5d8aBFMFs","outputId":"5db9eaba-f238-467d-b88e-fa6951f9739e"},"outputs":[{"name":"stdout","output_type":"stream","text":["Is CUDA available: True\n","CUDA version: 11.8\n","Number of GPUs: 1\n","GPU Name: NVIDIA GeForce RTX 4070 Ti\n","Train dataset size: 19967\n","Test dataset size: 4992\n","Class names: ['cats', 'dogs']\n"]}],"source":["# Data augmentation and normalization for training\n","# Just normalization for validation\n","data_transforms = {\n","    'train': transforms.Compose([\n","        transforms.RandomResizedCrop(224),\n","        transforms.RandomHorizontalFlip(),\n","        transforms.ToTensor(),\n","        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n","    ]),\n","    'test': transforms.Compose([\n","        transforms.Resize(256),\n","        transforms.CenterCrop(224),\n","        transforms.ToTensor(),\n","        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n","    ]),\n","}\n","\n","data_dir = 'cat_dog_dataset'\n","\n","# Create a full dataset and then split it\n","full_dataset = datasets.ImageFolder(data_dir, transform=data_transforms['train'])\n","\n","# Splitting indices for train and test sets\n","train_indices, test_indices = train_test_split(list(range(len(full_dataset))), test_size=0.2, random_state=100)\n","\n","# Creating train and test subsets\n","train_dataset = Subset(full_dataset, train_indices)\n","test_dataset = Subset(full_dataset, test_indices)\n","\n","# Applying appropriate transformations\n","train_dataset.dataset.transform = data_transforms['train']\n","test_dataset.dataset.transform = data_transforms['test']\n","\n","# Data loaders\n","dataloaders = {\n","    'train': DataLoader(train_dataset, batch_size=6, shuffle=True, num_workers=4),\n","    'test': DataLoader(test_dataset, batch_size=6, shuffle=False, num_workers=4)\n","}\n","\n","dataset_sizes = {\n","    'train': len(train_dataset),\n","    'test': len(test_dataset)\n","}\n","\n","class_names = full_dataset.classes\n","\n","device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","print(\"Is CUDA available:\", torch.cuda.is_available())\n","print(\"CUDA version:\", torch.version.cuda)\n","print(\"Number of GPUs:\", torch.cuda.device_count())\n","print(\"GPU Name:\", torch.cuda.get_device_name(0))\n","# Verify that the dataloaders are working correctly\n","print(f'Train dataset size: {dataset_sizes[\"train\"]}')\n","print(f'Test dataset size: {dataset_sizes[\"test\"]}')\n","print(f'Class names: {class_names}')"]},{"cell_type":"code","execution_count":9,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":11,"status":"ok","timestamp":1683496905712,"user":{"displayName":"Purnasai Gudikandula","userId":"02824392492878909733"},"user_tz":-330},"id":"ETyB-ag-GcWN","outputId":"ad67a7b3-783a-40fb-a6ac-ccc0fb3239c7"},"outputs":[{"data":{"text/plain":["{'train': <torch.utils.data.dataloader.DataLoader at 0x258fe20f140>,\n"," 'test': <torch.utils.data.dataloader.DataLoader at 0x258fe20fc80>}"]},"execution_count":9,"metadata":{},"output_type":"execute_result"}],"source":["dataloaders"]},{"cell_type":"markdown","metadata":{"id":"NyaNnftEH278"},"source":["Model\n"]},{"cell_type":"code","execution_count":10,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":602,"status":"ok","timestamp":1683496906306,"user":{"displayName":"Purnasai Gudikandula","userId":"02824392492878909733"},"user_tz":-330},"id":"bz4BJWf2H7I2","outputId":"874d3483-09d3-4a01-f421-3ea7a061ceba"},"outputs":[{"name":"stderr","output_type":"stream","text":["Using cache found in C:\\Users\\Yaniv/.cache\\torch\\hub\\facebookresearch_dinov2_main\n","C:\\Users\\Yaniv/.cache\\torch\\hub\\facebookresearch_dinov2_main\\dinov2\\layers\\swiglu_ffn.py:51: UserWarning: xFormers is not available (SwiGLU)\n","  warnings.warn(\"xFormers is not available (SwiGLU)\")\n","C:\\Users\\Yaniv/.cache\\torch\\hub\\facebookresearch_dinov2_main\\dinov2\\layers\\attention.py:33: UserWarning: xFormers is not available (Attention)\n","  warnings.warn(\"xFormers is not available (Attention)\")\n","C:\\Users\\Yaniv/.cache\\torch\\hub\\facebookresearch_dinov2_main\\dinov2\\layers\\block.py:40: UserWarning: xFormers is not available (Block)\n","  warnings.warn(\"xFormers is not available (Block)\")\n"]}],"source":["# load dino model\n","dinov2_vits14 = torch.hub.load('facebookresearch/dinov2', 'dinov2_vits14')"]},{"cell_type":"code","execution_count":11,"metadata":{"id":"UOuW0RPcH5Mf"},"outputs":[],"source":["class DinoVisionTransformerClassifier(nn.Module):\n","    def __init__(self):\n","        super(DinoVisionTransformerClassifier, self).__init__()\n","        self.transformer = dinov2_vits14\n","        self.classifier = nn.Sequential(\n","            nn.Linear(384, 256),\n","            nn.ReLU(),\n","            nn.Linear(256, 2)\n","        )\n","    \n","    def forward(self, x):\n","        x = self.transformer(x)\n","        x = self.transformer.norm(x)\n","        x = self.classifier(x)\n","        return x\n"]},{"cell_type":"code","execution_count":12,"metadata":{"id":"q4mkAkptHuEp"},"outputs":[],"source":["import torch.optim as optim\n","\n","model = DinoVisionTransformerClassifier()\n","\n","\n","model1 = models.resnet18(weights='IMAGENET1K_V1')\n","num_ftrs = model1.fc.in_features\n","model1.fc = nn.Linear(num_ftrs, 2)\n","model1 = model1.to(device)\n","\n","\n","criterion = nn.CrossEntropyLoss()\n","# optimizer = optim.SGD(model.parameters(), lr=0.0001, momentum=0.9)\n","optimizer = optim.Adam(model.parameters(), lr=0.000001)"]},{"cell_type":"code","execution_count":13,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":22,"status":"ok","timestamp":1683496911748,"user":{"displayName":"Purnasai Gudikandula","userId":"02824392492878909733"},"user_tz":-330},"id":"qA5rwAx5Ih9m","outputId":"c9d76628-5252-4457-d6de-b9dc64d3543b"},"outputs":[{"data":{"text/plain":["3328"]},"execution_count":13,"metadata":{},"output_type":"execute_result"}],"source":["len(dataloaders[\"train\"])"]},{"cell_type":"code","execution_count":14,"metadata":{"id":"nJubpBSGJgHK"},"outputs":[],"source":["model = model.to(device)"]},{"cell_type":"markdown","metadata":{"id":"E4cldJzNNgGX"},"source":["Train"]},{"cell_type":"code","execution_count":17,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":65243,"status":"ok","timestamp":1683496976973,"user":{"displayName":"Purnasai Gudikandula","userId":"02824392492878909733"},"user_tz":-330},"id":"jg78X2ffHC9Z","outputId":"1eb6a11e-7e89-4018-d38b-61329821255e"},"outputs":[{"name":"stdout","output_type":"stream","text":["[1,    50] loss: 0.007\n","[1,   100] loss: 0.004\n","[1,   150] loss: 0.003\n","[1,   200] loss: 0.011\n","[1,   250] loss: 0.001\n","[1,   300] loss: 0.007\n","[1,   350] loss: 0.006\n","[1,   400] loss: 0.004\n","[1,   450] loss: 0.002\n","[1,   500] loss: 0.000\n","[1,   550] loss: 0.001\n","[1,   600] loss: 0.001\n","[1,   650] loss: 0.008\n","[1,   700] loss: 0.004\n","[1,   750] loss: 0.001\n","[1,   800] loss: 0.004\n","[1,   850] loss: 0.000\n","[1,   900] loss: 0.001\n","[1,   950] loss: 0.001\n","[1,  1000] loss: 0.001\n","[1,  1050] loss: 0.000\n","[1,  1100] loss: 0.001\n","[1,  1150] loss: 0.001\n","[1,  1200] loss: 0.009\n","[1,  1250] loss: 0.016\n","[1,  1300] loss: 0.001\n","[1,  1350] loss: 0.018\n","[1,  1400] loss: 0.003\n","[1,  1450] loss: 0.029\n","[1,  1500] loss: 0.001\n","[1,  1550] loss: 0.006\n","[1,  1600] loss: 0.002\n","[1,  1650] loss: 0.001\n","[1,  1700] loss: 0.002\n","[1,  1750] loss: 0.001\n","[1,  1800] loss: 0.001\n","[1,  1850] loss: 0.008\n","[1,  1900] loss: 0.006\n","[1,  1950] loss: 0.003\n","[1,  2000] loss: 0.002\n","[1,  2050] loss: 0.002\n","[1,  2100] loss: 0.000\n","[1,  2150] loss: 0.000\n","[1,  2200] loss: 0.018\n","[1,  2250] loss: 0.004\n","[1,  2300] loss: 0.001\n","[1,  2350] loss: 0.029\n","[1,  2400] loss: 0.005\n","[1,  2450] loss: 0.000\n","[1,  2500] loss: 0.005\n","[1,  2550] loss: 0.007\n","[1,  2600] loss: 0.017\n","[1,  2650] loss: 0.002\n","[1,  2700] loss: 0.002\n","[1,  2750] loss: 0.005\n","[1,  2800] loss: 0.002\n","[1,  2850] loss: 0.001\n","[1,  2900] loss: 0.001\n","[1,  2950] loss: 0.005\n","[1,  3000] loss: 0.000\n","[1,  3050] loss: 0.004\n","[1,  3100] loss: 0.001\n","[1,  3150] loss: 0.000\n","[1,  3200] loss: 0.001\n","[1,  3250] loss: 0.000\n","[1,  3300] loss: 0.000\n","[2,    50] loss: 0.000\n","[2,   100] loss: 0.001\n","[2,   150] loss: 0.000\n","[2,   200] loss: 0.001\n","[2,   250] loss: 0.000\n","[2,   300] loss: 0.001\n","[2,   350] loss: 0.002\n","[2,   400] loss: 0.000\n","[2,   450] loss: 0.000\n","[2,   500] loss: 0.000\n","[2,   550] loss: 0.000\n","[2,   600] loss: 0.011\n","[2,   650] loss: 0.018\n","[2,   700] loss: 0.007\n","[2,   750] loss: 0.043\n","[2,   800] loss: 0.001\n","[2,   850] loss: 0.001\n","[2,   900] loss: 0.001\n","[2,   950] loss: 0.001\n","[2,  1000] loss: 0.001\n","[2,  1050] loss: 0.000\n","[2,  1100] loss: 0.001\n","[2,  1150] loss: 0.000\n","[2,  1200] loss: 0.001\n","[2,  1250] loss: 0.006\n","[2,  1300] loss: 0.008\n","[2,  1350] loss: 0.001\n","[2,  1400] loss: 0.000\n","[2,  1450] loss: 0.003\n","[2,  1500] loss: 0.001\n","[2,  1550] loss: 0.001\n","[2,  1600] loss: 0.001\n","[2,  1650] loss: 0.007\n","[2,  1700] loss: 0.000\n","[2,  1750] loss: 0.000\n","[2,  1800] loss: 0.026\n","[2,  1850] loss: 0.001\n","[2,  1900] loss: 0.001\n","[2,  1950] loss: 0.000\n","[2,  2000] loss: 0.001\n","[2,  2050] loss: 0.001\n","[2,  2100] loss: 0.000\n","[2,  2150] loss: 0.000\n","[2,  2200] loss: 0.001\n","[2,  2250] loss: 0.000\n","[2,  2300] loss: 0.001\n","[2,  2350] loss: 0.001\n","[2,  2400] loss: 0.000\n","[2,  2450] loss: 0.000\n","[2,  2500] loss: 0.001\n","[2,  2550] loss: 0.000\n","[2,  2600] loss: 0.000\n","[2,  2650] loss: 0.000\n","[2,  2700] loss: 0.001\n","[2,  2750] loss: 0.001\n","[2,  2800] loss: 0.001\n","[2,  2850] loss: 0.001\n","[2,  2900] loss: 0.000\n","[2,  2950] loss: 0.008\n","[2,  3000] loss: 0.020\n","[2,  3050] loss: 0.001\n","[2,  3100] loss: 0.000\n","[2,  3150] loss: 0.002\n","[2,  3200] loss: 0.003\n","[2,  3250] loss: 0.001\n","[2,  3300] loss: 0.001\n","[3,    50] loss: 0.001\n","[3,   100] loss: 0.000\n","[3,   150] loss: 0.000\n","[3,   200] loss: 0.001\n","[3,   250] loss: 0.001\n","[3,   300] loss: 0.000\n","[3,   350] loss: 0.022\n","[3,   400] loss: 0.002\n","[3,   450] loss: 0.001\n","[3,   500] loss: 0.000\n","[3,   550] loss: 0.001\n","[3,   600] loss: 0.000\n","[3,   650] loss: 0.000\n","[3,   700] loss: 0.006\n","[3,   750] loss: 0.009\n","[3,   800] loss: 0.003\n","[3,   850] loss: 0.001\n","[3,   900] loss: 0.002\n","[3,   950] loss: 0.001\n","[3,  1000] loss: 0.009\n","[3,  1050] loss: 0.000\n","[3,  1100] loss: 0.001\n","[3,  1150] loss: 0.002\n","[3,  1200] loss: 0.000\n","[3,  1250] loss: 0.000\n","[3,  1300] loss: 0.000\n","[3,  1350] loss: 0.000\n","[3,  1400] loss: 0.000\n","[3,  1450] loss: 0.000\n","[3,  1500] loss: 0.000\n","[3,  1550] loss: 0.000\n","[3,  1600] loss: 0.001\n","[3,  1650] loss: 0.000\n","[3,  1700] loss: 0.007\n","[3,  1750] loss: 0.028\n","[3,  1800] loss: 0.002\n","[3,  1850] loss: 0.001\n","[3,  1900] loss: 0.001\n","[3,  1950] loss: 0.006\n","[3,  2000] loss: 0.007\n","[3,  2050] loss: 0.002\n","[3,  2100] loss: 0.000\n","[3,  2150] loss: 0.001\n","[3,  2200] loss: 0.000\n","[3,  2250] loss: 0.000\n","[3,  2300] loss: 0.000\n","[3,  2350] loss: 0.003\n","[3,  2400] loss: 0.002\n","[3,  2450] loss: 0.002\n","[3,  2500] loss: 0.001\n","[3,  2550] loss: 0.000\n","[3,  2600] loss: 0.000\n","[3,  2650] loss: 0.001\n","[3,  2700] loss: 0.001\n","[3,  2750] loss: 0.000\n","[3,  2800] loss: 0.000\n","[3,  2850] loss: 0.000\n","[3,  2900] loss: 0.000\n","[3,  2950] loss: 0.000\n","[3,  3000] loss: 0.001\n","[3,  3050] loss: 0.000\n","[3,  3100] loss: 0.000\n","[3,  3150] loss: 0.000\n","[3,  3200] loss: 0.000\n","[3,  3250] loss: 0.000\n","[3,  3300] loss: 0.000\n","[4,    50] loss: 0.000\n","[4,   100] loss: 0.000\n","[4,   150] loss: 0.016\n","[4,   200] loss: 0.000\n","[4,   250] loss: 0.000\n","[4,   300] loss: 0.000\n","[4,   350] loss: 0.000\n","[4,   400] loss: 0.000\n","[4,   450] loss: 0.000\n","[4,   500] loss: 0.000\n","[4,   550] loss: 0.000\n","[4,   600] loss: 0.000\n","[4,   650] loss: 0.000\n","[4,   700] loss: 0.000\n","[4,   750] loss: 0.000\n","[4,   800] loss: 0.000\n","[4,   850] loss: 0.000\n","[4,   900] loss: 0.000\n","[4,   950] loss: 0.000\n","[4,  1000] loss: 0.000\n","[4,  1050] loss: 0.000\n","[4,  1100] loss: 0.000\n","[4,  1150] loss: 0.000\n","[4,  1200] loss: 0.000\n","[4,  1250] loss: 0.000\n","[4,  1300] loss: 0.000\n","[4,  1350] loss: 0.000\n","[4,  1400] loss: 0.000\n","[4,  1450] loss: 0.000\n","[4,  1500] loss: 0.000\n","[4,  1550] loss: 0.000\n","[4,  1600] loss: 0.000\n","[4,  1650] loss: 0.012\n","[4,  1700] loss: 0.001\n","[4,  1750] loss: 0.000\n","[4,  1800] loss: 0.000\n","[4,  1850] loss: 0.005\n","[4,  1900] loss: 0.000\n","[4,  1950] loss: 0.003\n","[4,  2000] loss: 0.026\n","[4,  2050] loss: 0.004\n","[4,  2100] loss: 0.003\n","[4,  2150] loss: 0.001\n","[4,  2200] loss: 0.029\n","[4,  2250] loss: 0.001\n","[4,  2300] loss: 0.010\n","[4,  2350] loss: 0.010\n","[4,  2400] loss: 0.011\n","[4,  2450] loss: 0.002\n","[4,  2500] loss: 0.019\n","[4,  2550] loss: 0.001\n","[4,  2600] loss: 0.003\n","[4,  2650] loss: 0.001\n","[4,  2700] loss: 0.001\n","[4,  2750] loss: 0.001\n","[4,  2800] loss: 0.001\n","[4,  2850] loss: 0.001\n","[4,  2900] loss: 0.000\n","[4,  2950] loss: 0.005\n","[4,  3000] loss: 0.002\n","[4,  3050] loss: 0.001\n","[4,  3100] loss: 0.000\n","[4,  3150] loss: 0.000\n","[4,  3200] loss: 0.000\n","[4,  3250] loss: 0.012\n","[4,  3300] loss: 0.000\n","[5,    50] loss: 0.001\n","[5,   100] loss: 0.003\n","[5,   150] loss: 0.000\n","[5,   200] loss: 0.000\n","[5,   250] loss: 0.000\n","[5,   300] loss: 0.010\n","[5,   350] loss: 0.000\n","[5,   400] loss: 0.000\n","[5,   450] loss: 0.000\n","[5,   500] loss: 0.011\n","[5,   550] loss: 0.000\n","[5,   600] loss: 0.001\n","[5,   650] loss: 0.000\n","[5,   700] loss: 0.000\n","[5,   750] loss: 0.000\n","[5,   800] loss: 0.000\n","[5,   850] loss: 0.000\n","[5,   900] loss: 0.000\n","[5,   950] loss: 0.000\n","[5,  1000] loss: 0.000\n","[5,  1050] loss: 0.000\n","[5,  1100] loss: 0.000\n","[5,  1150] loss: 0.000\n","[5,  1200] loss: 0.000\n","[5,  1250] loss: 0.000\n","[5,  1300] loss: 0.000\n","[5,  1350] loss: 0.000\n","[5,  1400] loss: 0.000\n","[5,  1450] loss: 0.000\n","[5,  1500] loss: 0.000\n","[5,  1550] loss: 0.000\n","[5,  1600] loss: 0.000\n","[5,  1650] loss: 0.000\n","[5,  1700] loss: 0.000\n","[5,  1750] loss: 0.000\n","[5,  1800] loss: 0.000\n","[5,  1850] loss: 0.000\n","[5,  1900] loss: 0.000\n","[5,  1950] loss: 0.000\n","[5,  2000] loss: 0.000\n","[5,  2050] loss: 0.000\n","[5,  2100] loss: 0.000\n","[5,  2150] loss: 0.000\n","[5,  2200] loss: 0.000\n","[5,  2250] loss: 0.000\n","[5,  2300] loss: 0.000\n","[5,  2350] loss: 0.000\n","[5,  2400] loss: 0.000\n","[5,  2450] loss: 0.000\n","[5,  2500] loss: 0.000\n","[5,  2550] loss: 0.000\n","[5,  2600] loss: 0.000\n","[5,  2650] loss: 0.000\n","[5,  2700] loss: 0.000\n","[5,  2750] loss: 0.000\n","[5,  2800] loss: 0.000\n","[5,  2850] loss: 0.000\n","[5,  2900] loss: 0.000\n","[5,  2950] loss: 0.000\n","[5,  3000] loss: 0.000\n","[5,  3050] loss: 0.000\n","[5,  3100] loss: 0.000\n","[5,  3150] loss: 0.000\n","[5,  3200] loss: 0.000\n","[5,  3250] loss: 0.000\n","[5,  3300] loss: 0.000\n","[6,    50] loss: 0.000\n","[6,   100] loss: 0.000\n","[6,   150] loss: 0.000\n","[6,   200] loss: 0.000\n","[6,   250] loss: 0.000\n","[6,   300] loss: 0.000\n","[6,   350] loss: 0.000\n","[6,   400] loss: 0.001\n","[6,   450] loss: 0.000\n","[6,   500] loss: 0.000\n","[6,   550] loss: 0.000\n","[6,   600] loss: 0.000\n","[6,   650] loss: 0.000\n","[6,   700] loss: 0.000\n","[6,   750] loss: 0.000\n","[6,   800] loss: 0.000\n","[6,   850] loss: 0.000\n","[6,   900] loss: 0.000\n","[6,   950] loss: 0.000\n","[6,  1000] loss: 0.000\n","[6,  1050] loss: 0.000\n","[6,  1100] loss: 0.000\n","[6,  1150] loss: 0.000\n","[6,  1200] loss: 0.000\n","[6,  1250] loss: 0.005\n","[6,  1300] loss: 0.001\n","[6,  1350] loss: 0.000\n","[6,  1400] loss: 0.000\n","[6,  1450] loss: 0.000\n","[6,  1500] loss: 0.000\n","[6,  1550] loss: 0.000\n","[6,  1600] loss: 0.000\n","[6,  1650] loss: 0.000\n","[6,  1700] loss: 0.000\n","[6,  1750] loss: 0.000\n","[6,  1800] loss: 0.000\n","[6,  1850] loss: 0.000\n","[6,  1900] loss: 0.000\n","[6,  1950] loss: 0.000\n","[6,  2000] loss: 0.000\n","[6,  2050] loss: 0.000\n","[6,  2100] loss: 0.000\n","[6,  2150] loss: 0.000\n","[6,  2200] loss: 0.037\n","[6,  2250] loss: 0.007\n","[6,  2300] loss: 0.010\n","[6,  2350] loss: 0.004\n","[6,  2400] loss: 0.011\n","[6,  2450] loss: 0.015\n","[6,  2500] loss: 0.002\n","[6,  2550] loss: 0.004\n","[6,  2600] loss: 0.000\n","[6,  2650] loss: 0.001\n","[6,  2700] loss: 0.004\n","[6,  2750] loss: 0.002\n","[6,  2800] loss: 0.004\n","[6,  2850] loss: 0.000\n","[6,  2900] loss: 0.002\n","[6,  2950] loss: 0.001\n","[6,  3000] loss: 0.000\n","[6,  3050] loss: 0.000\n","[6,  3100] loss: 0.001\n","[6,  3150] loss: 0.000\n","[6,  3200] loss: 0.014\n","[6,  3250] loss: 0.002\n","[6,  3300] loss: 0.004\n","Finished Training\n"]}],"source":["for epoch in range(6):  # loop over the dataset multiple times\n","\n","    running_loss = 0.0\n","    for i, data in enumerate(dataloaders[\"train\"], 0):\n","        # get the inputs; data is a list of [inputs, labels]\n","        inputs, labels = data\n","\n","        # zero the parameter gradients\n","        optimizer.zero_grad()\n","\n","        # forward + backward + optimize\n","        outputs = model(inputs.to(device))\n","        loss = criterion(outputs, labels.to(device))\n","        loss.backward()\n","        optimizer.step()\n","\n","        # print statistics\n","        running_loss += loss.item()\n","        if i % 50 == 49:    # print every 2000 mini-batches\n","            print(f'[{epoch + 1}, {i + 1:5d}] loss: {running_loss / 50:.3f}')\n","            running_loss = 0.0\n","\n","print('Finished Training')"]},{"cell_type":"markdown","metadata":{"id":"e7GHOqmINdv5"},"source":["Testing"]},{"cell_type":"code","execution_count":18,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":722,"status":"ok","timestamp":1683496977677,"user":{"displayName":"Purnasai Gudikandula","userId":"02824392492878909733"},"user_tz":-330},"id":"-N9x3KW6I8JF","outputId":"84bea07f-4cb9-45f6-c879-a68a7d69a06d"},"outputs":[{"name":"stdout","output_type":"stream","text":["Accuracy of the network on the 4992 test images: 99 %\n"]}],"source":["correct = 0\n","total = 0\n","# since we're not training, we don't need to calculate the gradients for our outputs\n","with torch.no_grad():\n","    for data in dataloaders[\"test\"]:\n","        images, labels = data\n","        # calculate outputs by running images through the network\n","        outputs = model(images.to(device))\n","        # the class with the highest energy is what we choose as prediction\n","        _, predicted = torch.max(outputs.data, 1)\n","        total += labels.size(0)\n","        correct += (predicted.to(\"cpu\") == labels).sum().item()\n","\n","print(f'Accuracy of the network on the {len(dataloaders[\"test\"])*6} test images: {100 * correct // total} %')"]},{"cell_type":"markdown","metadata":{"id":"v01LGzPiOMkU"},"source":["Resnet classification"]},{"cell_type":"code","execution_count":19,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":28852,"status":"ok","timestamp":1683497006527,"user":{"displayName":"Purnasai Gudikandula","userId":"02824392492878909733"},"user_tz":-330},"id":"mOrr7ty8OL5c","outputId":"71c35bc9-03a9-4fe5-d591-221eb7717f92"},"outputs":[{"name":"stdout","output_type":"stream","text":["[1,    50] loss: 0.802\n","[1,   100] loss: 0.790\n","[1,   150] loss: 0.798\n","[1,   200] loss: 0.782\n","[1,   250] loss: 0.788\n","[1,   300] loss: 0.830\n","[1,   350] loss: 0.822\n","[1,   400] loss: 0.780\n","[1,   450] loss: 0.783\n","[1,   500] loss: 0.797\n","[1,   550] loss: 0.786\n","[1,   600] loss: 0.813\n","[1,   650] loss: 0.787\n","[1,   700] loss: 0.754\n","[1,   750] loss: 0.818\n","[1,   800] loss: 0.818\n","[1,   850] loss: 0.798\n","[1,   900] loss: 0.815\n","[1,   950] loss: 0.809\n","[1,  1000] loss: 0.811\n","[1,  1050] loss: 0.795\n","[1,  1100] loss: 0.770\n","[1,  1150] loss: 0.771\n","[1,  1200] loss: 0.810\n","[1,  1250] loss: 0.785\n","[1,  1300] loss: 0.793\n","[1,  1350] loss: 0.825\n","[1,  1400] loss: 0.808\n","[1,  1450] loss: 0.775\n","[1,  1500] loss: 0.822\n","[1,  1550] loss: 0.798\n","[1,  1600] loss: 0.799\n","[1,  1650] loss: 0.790\n","[1,  1700] loss: 0.795\n","[1,  1750] loss: 0.793\n","[1,  1800] loss: 0.797\n","[1,  1850] loss: 0.789\n","[1,  1900] loss: 0.796\n","[1,  1950] loss: 0.813\n","[1,  2000] loss: 0.822\n","[1,  2050] loss: 0.805\n","[1,  2100] loss: 0.775\n","[1,  2150] loss: 0.786\n","[1,  2200] loss: 0.790\n","[1,  2250] loss: 0.795\n","[1,  2300] loss: 0.804\n","[1,  2350] loss: 0.788\n","[1,  2400] loss: 0.829\n","[1,  2450] loss: 0.813\n","[1,  2500] loss: 0.806\n","[1,  2550] loss: 0.811\n","[1,  2600] loss: 0.791\n","[1,  2650] loss: 0.798\n","[1,  2700] loss: 0.803\n","[1,  2750] loss: 0.798\n","[1,  2800] loss: 0.814\n","[1,  2850] loss: 0.821\n","[1,  2900] loss: 0.806\n","[1,  2950] loss: 0.843\n","[1,  3000] loss: 0.804\n","[1,  3050] loss: 0.815\n","[1,  3100] loss: 0.780\n","[1,  3150] loss: 0.799\n","[1,  3200] loss: 0.818\n","[1,  3250] loss: 0.818\n","[1,  3300] loss: 0.808\n","[2,    50] loss: 0.809\n","[2,   100] loss: 0.794\n","[2,   150] loss: 0.788\n","[2,   200] loss: 0.812\n","[2,   250] loss: 0.800\n","[2,   300] loss: 0.810\n","[2,   350] loss: 0.771\n","[2,   400] loss: 0.788\n","[2,   450] loss: 0.787\n","[2,   500] loss: 0.798\n","[2,   550] loss: 0.791\n","[2,   600] loss: 0.792\n","[2,   650] loss: 0.818\n","[2,   700] loss: 0.810\n","[2,   750] loss: 0.842\n","[2,   800] loss: 0.778\n","[2,   850] loss: 0.782\n","[2,   900] loss: 0.807\n","[2,   950] loss: 0.811\n","[2,  1000] loss: 0.791\n","[2,  1050] loss: 0.803\n","[2,  1100] loss: 0.779\n","[2,  1150] loss: 0.799\n","[2,  1200] loss: 0.802\n","[2,  1250] loss: 0.804\n","[2,  1300] loss: 0.774\n","[2,  1350] loss: 0.816\n","[2,  1400] loss: 0.795\n","[2,  1450] loss: 0.786\n","[2,  1500] loss: 0.803\n","[2,  1550] loss: 0.821\n","[2,  1600] loss: 0.785\n","[2,  1650] loss: 0.832\n","[2,  1700] loss: 0.815\n","[2,  1750] loss: 0.800\n","[2,  1800] loss: 0.819\n","[2,  1850] loss: 0.796\n","[2,  1900] loss: 0.799\n","[2,  1950] loss: 0.809\n","[2,  2000] loss: 0.775\n","[2,  2050] loss: 0.781\n","[2,  2100] loss: 0.775\n","[2,  2150] loss: 0.817\n","[2,  2200] loss: 0.808\n","[2,  2250] loss: 0.792\n","[2,  2300] loss: 0.802\n","[2,  2350] loss: 0.817\n","[2,  2400] loss: 0.818\n","[2,  2450] loss: 0.807\n","[2,  2500] loss: 0.806\n","[2,  2550] loss: 0.808\n","[2,  2600] loss: 0.784\n","[2,  2650] loss: 0.812\n","[2,  2700] loss: 0.824\n","[2,  2750] loss: 0.808\n","[2,  2800] loss: 0.824\n","[2,  2850] loss: 0.784\n","[2,  2900] loss: 0.819\n","[2,  2950] loss: 0.795\n","[2,  3000] loss: 0.809\n","[2,  3050] loss: 0.789\n","[2,  3100] loss: 0.789\n","[2,  3150] loss: 0.789\n","[2,  3200] loss: 0.785\n","[2,  3250] loss: 0.811\n","[2,  3300] loss: 0.802\n","[3,    50] loss: 0.809\n","[3,   100] loss: 0.810\n","[3,   150] loss: 0.825\n","[3,   200] loss: 0.792\n","[3,   250] loss: 0.818\n","[3,   300] loss: 0.812\n","[3,   350] loss: 0.789\n","[3,   400] loss: 0.796\n","[3,   450] loss: 0.786\n","[3,   500] loss: 0.794\n","[3,   550] loss: 0.795\n","[3,   600] loss: 0.798\n","[3,   650] loss: 0.802\n","[3,   700] loss: 0.791\n","[3,   750] loss: 0.801\n","[3,   800] loss: 0.816\n","[3,   850] loss: 0.767\n","[3,   900] loss: 0.840\n","[3,   950] loss: 0.831\n","[3,  1000] loss: 0.817\n","[3,  1050] loss: 0.815\n","[3,  1100] loss: 0.811\n","[3,  1150] loss: 0.785\n","[3,  1200] loss: 0.809\n","[3,  1250] loss: 0.804\n","[3,  1300] loss: 0.821\n","[3,  1350] loss: 0.824\n","[3,  1400] loss: 0.783\n","[3,  1450] loss: 0.806\n","[3,  1500] loss: 0.812\n","[3,  1550] loss: 0.800\n","[3,  1600] loss: 0.789\n","[3,  1650] loss: 0.823\n","[3,  1700] loss: 0.834\n","[3,  1750] loss: 0.801\n","[3,  1800] loss: 0.784\n","[3,  1850] loss: 0.782\n","[3,  1900] loss: 0.825\n","[3,  1950] loss: 0.799\n","[3,  2000] loss: 0.782\n","[3,  2050] loss: 0.794\n","[3,  2100] loss: 0.807\n","[3,  2150] loss: 0.765\n","[3,  2200] loss: 0.781\n","[3,  2250] loss: 0.798\n","[3,  2300] loss: 0.800\n","[3,  2350] loss: 0.776\n","[3,  2400] loss: 0.822\n","[3,  2450] loss: 0.821\n","[3,  2500] loss: 0.814\n","[3,  2550] loss: 0.792\n","[3,  2600] loss: 0.790\n","[3,  2650] loss: 0.776\n","[3,  2700] loss: 0.798\n","[3,  2750] loss: 0.793\n","[3,  2800] loss: 0.845\n","[3,  2850] loss: 0.779\n","[3,  2900] loss: 0.813\n","[3,  2950] loss: 0.806\n","[3,  3000] loss: 0.813\n","[3,  3050] loss: 0.771\n","[3,  3100] loss: 0.812\n","[3,  3150] loss: 0.759\n","[3,  3200] loss: 0.820\n","[3,  3250] loss: 0.778\n","[3,  3300] loss: 0.823\n","[4,    50] loss: 0.809\n","[4,   100] loss: 0.779\n","[4,   150] loss: 0.789\n","[4,   200] loss: 0.803\n","[4,   250] loss: 0.787\n","[4,   300] loss: 0.782\n","[4,   350] loss: 0.828\n","[4,   400] loss: 0.783\n","[4,   450] loss: 0.799\n","[4,   500] loss: 0.794\n","[4,   550] loss: 0.830\n","[4,   600] loss: 0.781\n","[4,   650] loss: 0.825\n","[4,   700] loss: 0.792\n","[4,   750] loss: 0.817\n","[4,   800] loss: 0.809\n","[4,   850] loss: 0.810\n","[4,   900] loss: 0.792\n","[4,   950] loss: 0.803\n","[4,  1000] loss: 0.800\n","[4,  1050] loss: 0.763\n","[4,  1100] loss: 0.813\n","[4,  1150] loss: 0.783\n","[4,  1200] loss: 0.813\n","[4,  1250] loss: 0.808\n","[4,  1300] loss: 0.771\n","[4,  1350] loss: 0.819\n","[4,  1400] loss: 0.793\n","[4,  1450] loss: 0.805\n","[4,  1500] loss: 0.828\n","[4,  1550] loss: 0.797\n","[4,  1600] loss: 0.827\n","[4,  1650] loss: 0.801\n","[4,  1700] loss: 0.829\n","[4,  1750] loss: 0.805\n","[4,  1800] loss: 0.814\n","[4,  1850] loss: 0.796\n","[4,  1900] loss: 0.799\n","[4,  1950] loss: 0.808\n","[4,  2000] loss: 0.833\n","[4,  2050] loss: 0.796\n","[4,  2100] loss: 0.768\n","[4,  2150] loss: 0.790\n","[4,  2200] loss: 0.813\n","[4,  2250] loss: 0.806\n","[4,  2300] loss: 0.789\n","[4,  2350] loss: 0.816\n","[4,  2400] loss: 0.804\n","[4,  2450] loss: 0.780\n","[4,  2500] loss: 0.805\n","[4,  2550] loss: 0.828\n","[4,  2600] loss: 0.801\n","[4,  2650] loss: 0.759\n","[4,  2700] loss: 0.804\n","[4,  2750] loss: 0.797\n","[4,  2800] loss: 0.775\n","[4,  2850] loss: 0.810\n","[4,  2900] loss: 0.789\n","[4,  2950] loss: 0.796\n","[4,  3000] loss: 0.813\n","[4,  3050] loss: 0.798\n","[4,  3100] loss: 0.795\n","[4,  3150] loss: 0.812\n","[4,  3200] loss: 0.809\n","[4,  3250] loss: 0.784\n","[4,  3300] loss: 0.822\n","[5,    50] loss: 0.794\n","[5,   100] loss: 0.833\n","[5,   150] loss: 0.800\n","[5,   200] loss: 0.770\n","[5,   250] loss: 0.792\n","[5,   300] loss: 0.783\n","[5,   350] loss: 0.797\n","[5,   400] loss: 0.799\n","[5,   450] loss: 0.772\n","[5,   500] loss: 0.781\n","[5,   550] loss: 0.820\n","[5,   600] loss: 0.774\n","[5,   650] loss: 0.805\n","[5,   700] loss: 0.838\n","[5,   750] loss: 0.808\n","[5,   800] loss: 0.817\n","[5,   850] loss: 0.798\n","[5,   900] loss: 0.832\n","[5,   950] loss: 0.800\n","[5,  1000] loss: 0.778\n","[5,  1050] loss: 0.834\n","[5,  1100] loss: 0.780\n","[5,  1150] loss: 0.821\n","[5,  1200] loss: 0.817\n","[5,  1250] loss: 0.790\n","[5,  1300] loss: 0.808\n","[5,  1350] loss: 0.803\n","[5,  1400] loss: 0.800\n","[5,  1450] loss: 0.821\n","[5,  1500] loss: 0.820\n","[5,  1550] loss: 0.786\n","[5,  1600] loss: 0.777\n","[5,  1650] loss: 0.817\n","[5,  1700] loss: 0.820\n","[5,  1750] loss: 0.800\n","[5,  1800] loss: 0.800\n","[5,  1850] loss: 0.831\n","[5,  1900] loss: 0.823\n","[5,  1950] loss: 0.801\n","[5,  2000] loss: 0.811\n","[5,  2050] loss: 0.814\n","[5,  2100] loss: 0.800\n","[5,  2150] loss: 0.788\n","[5,  2200] loss: 0.822\n","[5,  2250] loss: 0.822\n","[5,  2300] loss: 0.790\n","[5,  2350] loss: 0.787\n","[5,  2400] loss: 0.797\n","[5,  2450] loss: 0.793\n","[5,  2500] loss: 0.782\n","[5,  2550] loss: 0.775\n","[5,  2600] loss: 0.809\n","[5,  2650] loss: 0.839\n","[5,  2700] loss: 0.766\n","[5,  2750] loss: 0.791\n","[5,  2800] loss: 0.807\n","[5,  2850] loss: 0.776\n","[5,  2900] loss: 0.805\n","[5,  2950] loss: 0.820\n","[5,  3000] loss: 0.789\n","[5,  3050] loss: 0.808\n","[5,  3100] loss: 0.793\n","[5,  3150] loss: 0.796\n","[5,  3200] loss: 0.775\n","[5,  3250] loss: 0.789\n","[5,  3300] loss: 0.794\n","[6,    50] loss: 0.804\n","[6,   100] loss: 0.779\n","[6,   150] loss: 0.812\n","[6,   200] loss: 0.776\n","[6,   250] loss: 0.834\n","[6,   300] loss: 0.802\n","[6,   350] loss: 0.787\n","[6,   400] loss: 0.781\n","[6,   450] loss: 0.775\n","[6,   500] loss: 0.835\n","[6,   550] loss: 0.810\n","[6,   600] loss: 0.797\n","[6,   650] loss: 0.827\n","[6,   700] loss: 0.781\n","[6,   750] loss: 0.793\n","[6,   800] loss: 0.825\n","[6,   850] loss: 0.809\n","[6,   900] loss: 0.782\n","[6,   950] loss: 0.809\n","[6,  1000] loss: 0.782\n","[6,  1050] loss: 0.780\n","[6,  1100] loss: 0.816\n","[6,  1150] loss: 0.781\n","[6,  1200] loss: 0.795\n","[6,  1250] loss: 0.785\n","[6,  1300] loss: 0.806\n","[6,  1350] loss: 0.792\n","[6,  1400] loss: 0.787\n","[6,  1450] loss: 0.792\n","[6,  1500] loss: 0.769\n","[6,  1550] loss: 0.802\n","[6,  1600] loss: 0.755\n","[6,  1650] loss: 0.793\n","[6,  1700] loss: 0.808\n","[6,  1750] loss: 0.783\n","[6,  1800] loss: 0.786\n","[6,  1850] loss: 0.805\n","[6,  1900] loss: 0.814\n","[6,  1950] loss: 0.781\n","[6,  2000] loss: 0.831\n","[6,  2050] loss: 0.812\n","[6,  2100] loss: 0.806\n","[6,  2150] loss: 0.836\n","[6,  2200] loss: 0.804\n","[6,  2250] loss: 0.809\n","[6,  2300] loss: 0.797\n","[6,  2350] loss: 0.792\n","[6,  2400] loss: 0.791\n","[6,  2450] loss: 0.804\n","[6,  2500] loss: 0.790\n","[6,  2550] loss: 0.803\n","[6,  2600] loss: 0.791\n","[6,  2650] loss: 0.780\n","[6,  2700] loss: 0.815\n","[6,  2750] loss: 0.802\n","[6,  2800] loss: 0.811\n","[6,  2850] loss: 0.822\n","[6,  2900] loss: 0.807\n","[6,  2950] loss: 0.806\n","[6,  3000] loss: 0.794\n","[6,  3050] loss: 0.781\n","[6,  3100] loss: 0.803\n","[6,  3150] loss: 0.815\n","[6,  3200] loss: 0.787\n","[6,  3250] loss: 0.788\n","[6,  3300] loss: 0.793\n","Finished Training\n"]}],"source":["model1 = model1.to(device)\n","\n","for epoch in range(6):  # loop over the dataset multiple times\n","\n","    running_loss = 0.0\n","    for i, data in enumerate(dataloaders[\"train\"], 0):\n","        # get the inputs; data is a list of [inputs, labels]\n","        inputs, labels = data\n","\n","        # zero the parameter gradients\n","        optimizer.zero_grad()\n","\n","        # forward + backward + optimize\n","        outputs = model1(inputs.to(device))\n","        loss = criterion(outputs, labels.to(device))\n","        loss.backward()\n","        optimizer.step()\n","\n","        # print statistics\n","        running_loss += loss.item()\n","        if i % 50 == 49:    # print every 2000 mini-batches\n","            print(f'[{epoch + 1}, {i + 1:5d}] loss: {running_loss / 50:.3f}')\n","            running_loss = 0.0\n","\n","print('Finished Training')"]},{"cell_type":"code","execution_count":20,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":621,"status":"ok","timestamp":1683497007108,"user":{"displayName":"Purnasai Gudikandula","userId":"02824392492878909733"},"user_tz":-330},"id":"p3CXNKijOZQE","outputId":"8c957893-b41b-4633-f3e7-399c6d1e676c"},"outputs":[{"name":"stdout","output_type":"stream","text":["Accuracy of the network on the 4992 test images: 39 %\n"]}],"source":["correct = 0\n","total = 0\n","# since we're not training, we don't need to calculate the gradients for our outputs\n","with torch.no_grad():\n","    for data in dataloaders[\"test\"]:\n","        images, labels = data\n","        # calculate outputs by running images through the network\n","        outputs = model1(images.to(device))\n","        # the class with the highest energy is what we choose as prediction\n","        _, predicted = torch.max(outputs.data, 1)\n","        total += labels.size(0)\n","        correct += (predicted.to(\"cpu\") == labels).sum().item()\n","\n","print(f'Accuracy of the network on the {len(dataloaders[\"test\"])*6} test images: {100 * correct // total} %')"]},{"cell_type":"code","execution_count":21,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":9,"status":"ok","timestamp":1683497040659,"user":{"displayName":"Purnasai Gudikandula","userId":"02824392492878909733"},"user_tz":-330},"id":"wTh86MY7PizA","outputId":"09374d03-7cc9-4a6a-ff7e-9b5dc833a36a"},"outputs":[{"data":{"text/plain":["1962"]},"execution_count":21,"metadata":{},"output_type":"execute_result"}],"source":["correct"]},{"cell_type":"code","execution_count":22,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":9,"status":"ok","timestamp":1683497043805,"user":{"displayName":"Purnasai Gudikandula","userId":"02824392492878909733"},"user_tz":-330},"id":"bl511gK5PjSd","outputId":"cf4e481b-6822-490d-fcd5-c051ff77a5bb"},"outputs":[{"data":{"text/plain":["4992"]},"execution_count":22,"metadata":{},"output_type":"execute_result"}],"source":["total"]}],"metadata":{"accelerator":"GPU","colab":{"authorship_tag":"ABX9TyNnGADzcxNkTkQO99rTLPJs","gpuType":"T4","provenance":[]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.3"}},"nbformat":4,"nbformat_minor":0}
